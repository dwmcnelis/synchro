This URL (http://bitly.com/nuvi-plz) is an http folder containing a list of zip files. Each zip file contains a bunch of xml files. Each xml file contains 1 news report.


Your application needs to download all of the zip files, extract out the xml files, and publish the content of each xml file to a redis list called “NEWS_XML”.


Make the application idempotent. We want to be able to run it multiple times but not get duplicate data in the redis list.


Designed as a gem: synchro

Redis can be running on an arbitary host/port if defined by environment variable:

$ export REDIS_URL=redis://:p4ssw0rd@10.0.1.1:6380/15

If not defined or passed in as option, will assume Redis listening on localhost, port 6379

Implementation does not use a redis list so as to add a performance optimization while processing repeated sychronizations.

Packages (zip file of xml articles) have their pusblished date (from feed page) cached in Redis by a key of the form "package:<PACKAGEID>". This allows for skipping the download time for the zip file, if the same version is aready downloaded.

Articles have their content cached in Redis by a key of the form "package:<PACKAGEID>:<ARTICLEID>" for direct access.

$ cd synchro
$ bundle
$ bundle console

To process feed directory:

2.1.8 :001 > Synchro::Reader.go("http://bitly.com/nuvi-plz")

To list packages in Redis cache:

2.1.8 :002 > Synchro::Reader.packages

To list articles in Redis cache:

2.1.8 :003 > Synchro::Reader.articles('1462888730938')

To fetch an article from Redis cache:

2.1.8 :003 > Synchro::Reader.article('1462888730938:0ea91d04f7abad70975936c2e40956f3')

To clear Redis cache (packages and articles only):

2.1.8 :004 > Synchro::Reader.flush

